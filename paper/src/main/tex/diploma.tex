\documentclass[14pt]{matmex-diploma-custom}

\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsmath}

\begin{document}
\filltitle{ru}{
    chair              = {Кафедра информационно-аналитических систем},
    title              = {Потоковая обработка данных},
    type               = {coursework},
    author             = {Трофимов Артем Владимирович, Маршалкин Никита Евгеньевич},
    supervisorPosition = {к.\,ф.-м.\,н., доцент},
    supervisor         = {Кураленок И.\,Е.},
    faculty            = {Математико-механический факультет}
}
\filltitle{en}{
    chair              = {Sub-Department of Analytical Information Systems},
    title              = {Stream-based data processing},
    type               = {coursework},
    author             = {Artem Trofimov, Marshalkin Nikita},
    supervisorPosition = {assistant professor},
    supervisor         = {Igor Kuralenok},
    faculty            = {Mathematics And Mechanics Faculty}
}
\maketitle

\tableofcontents

\section*{Введение}

Обработка и анализ больших объемов данных, на данный момент,  являются чрезвычайно важными и нетривиальными задачами, не имеющими универсального решения. Классическим подходом к их решению является применение так называемой пакетной обработки. При таком подходе весь набор данных разбивается на части меньшего объема, а они, в свою очередь, независимо обрабатываются. В конечном счете, все полученные результаты каждой части тем или иным образом совмещаются в итоговый результат. Примером организации пакетной обработки данных является модель MapReduce, предложенная компанией Google в 2004 году \cite{mapreduce}. На текущий момент существует ряд реализаций модели MapReduce с открытым исходным кодом, например, Apache Hadoop, Spark, Flink, и т.д. \cite{hadoop}\cite{spark}\cite{flink}.

Однако современные высоконагруженные системы и сервисы часто сталкиваются с задачами, которые требуют минимизировать время между получением входных данных и их обработкой. Примерами таких задач могут служить построение инвертированного индекса на новостных данных, алгоритмическая торговля, отслеживание дорожной ситуации для построения оптимального маршрута.  Очевидно, что пакетная обработка, в общем, и классическая модель MapReduce, в частности, не позволяют получить приемлемые результаты при такой постановке задачи. Таким образом, возникает задача потоковой обработки больших данных, то есть обработки данных, которые не доступны сразу в полном объеме, а последовательно поступают на вход и требуют скорейшей обработки.

В последнее время появился подход, называемый micro-batching, заключающийся в получении данных на вход либо порциями определенного размера, либо порциями, собранными за определенное время, последовательной их обработке и комбинировании результата в процессе выполнения и получения новой порции данных. Было показано, что модель MapReduce также может быть обобщена для использования в micro-batching системах. В качестве примера систем, поддерживающих micro-batching можно привести Apache Storm, Spark, Flink. Тем не менее, у указанного подхода и систем также есть ряд недостатков. Предполагается, что для достижения exactly-once  семантики результаты будут выданы только после обработки всей порции данных, что увеличивает задержку. К недостаткам можно также отнести недостаточную пропускную способность, недетерминированность и зависимость от источника данных. Более подробно проблемы существующих решений описаны в разделе 1.

В данной работе мы предлагаем модель организации потоковой обработки данных, которая позволяет решить некоторые проблемы существующих решений. В нашей модели ответственность за перепроигрывание данных при ошибках или падениях лежит на самой системе. Кроме того, мы отказываемся от классического  micro-batching и используем отслеживание минимального времени в системе для выдачи валидных результатов. Предлагаемая архитектура позволяет также добиться детерминированности.

\section{Существующие решения}

\subsection{Apache Storm}

Одним из первых проектов в области потоковой обработки данных был Apache Storm. Однако на данный момент, он практически не поддерживается и не используется на практике. Более того, в нем отсутствует поддержка "из коробки" высокоуровневых операций и exactly-once семантики.

\subsection{Apache Storm + Trident, Storm, Flink}

Основная проблема отмеченных систем в том, что при micro-batching приходится ждать обработке всей порции данных для достижения exactly-once семантики. Очевидно, такой подход негативно влияет на задержку (latency). Еще одним недостатком является то, что ответственность за перепроигрывание данных при падениях эти системы возлагают на источник данных. На данный момент распространенной практикой при использовании Apache Spark/Flink является использование Apache Kafka в качестве источника данных и механизма восстановления при падениях \cite{kafka}. Такой подход добавляет в систему еще один дополнительный элемент, что также ухудшает задержку. Наконец, эти решения не гарантируют детерминированность, то есть при разных их запусках могут получаться разные результаты.

\section{Постановка задачи}

Задача данной работы состоит из двух основных частей. Первая часть заключается в проектировании и описании нового подхода к потоковой обработке больших данных. Вторая состоит в том, чтобы реализовать этот подход в виде готовой программной системы. при проектировании мы руководствовались целями и идеями, описанными в разделе 2.1.

\subsection{Цели и идеи}

\subsubsection{Отказ от micro-batching}

Основной идеей является отказ от micro-batching и введение понятия adaptive micro-batching. Смысл adaptive micro-batching заключается в том, чтобы не привязывать выдачу результатов к полной обработке текущей порции. Вместо этого предлагается каждому входному элементу данных присвоить временную метку и во время работы системы поддерживать минимальное время, которое имеет какой-либо элемент в системе. Таким образом, при изменении минимального времени в системе можно выдавать результат, не дожидаясь обработки все порции. При этом, разделение на порции используется для того, чтобы на их границах сохранять состояние операций, которое может понадобиться при перепроигрывании.

\subsubsection{Exactly-once семантика}

За счет присваивания меток времени и использования хеширования может быть достигнута exactly-once семантика даже при ошибках/падениях и последующем перепроигрывании.

\subsubsection{Отказ от хранения состояния в бизнес-логике}

В нашем подходе предоставляемых операций достаточно для описания любой MapReduce задачи без необходимости сохранять состояния операций в бизнес-логике. Таким образом, вся функциональность по хранению состояний прозрачна для пользователя.

\subsubsection{Ответсвенность за перепроигрывание данных при ошибках/падениях}

Как было отмечено выше, распространенной практикой при использовании Apache Spark/Flink является использование Apache Kafka в качестве источника данных и механизма восстановления при падениях. Вместо этого, мы хотим возложить ответственность за перепроигрывание данных на саму систему.

\section{Модель и архитектура}

Главная сущность системы - это поток данных протекающий через граф, узлами которого являются операции, последовательные применяемые к данным, а ребра задают порядок выполнения.

Нагрузка распределяется по хешу от данных, то есть на каждом вычислительном модуле выполняется весь граф, а пересылка между ними происходит, если данные поменяли хеш. Благодаря этому горизонтальная масштабируемость достигается без внесения изменений в бизнес-логику.

Источником данных является фронт, процесс работающий на клиенте: на веб-фронте, на каком-либо сенсоре. Поскольку между порождением данных и попаданием в систему нет посредников, появляются полезные свойства: отсутствует задержка, которую не избежать при использовании брокеров сообщений, каждый входной элемент можем пометить “своим” временем, что вносит детерминизм, при повторной обработке гарантируется такой-же результат. Так же наличие единого времени позволяет отойти от концепции micro-batching, “выпускать” обработанные элементы из системы до завершения окна (транзакции, batch’а).

Состояние системы и координационная информация хранится в  Apache Zookeeper, тем самым делегируя проблемы распределенного консенсуса.

\subsection{Время}

В нашей системе мы различаем два времени: глобальное и локальное.

\textbf{Глобальное время} - время входа элемента в систему в наносекундах с начала эпохи. Важно, что время - строго монотонно в рамках одного фронта и два разных события имеют разное время независимо от фронта. Первое условие достигается использованием  монотонных часов (CLOCK\_MONOTONIC). Чтобы обеспечить различие времени на разных фронтах во время вносится номер фронта.

\[GlobalTime := (frontTs, frontId)\]

Глобальное время сравнивается лексикографически: время, потом номер фронта.

Гарантии на синхронизацию времени не требуется для корректной работы, но от этой разницы зависит нижняя граница задержки между событием и реакцией на него (появления данных на источнике и полной обработки).

\textbf{Локальное время} - логическое время каждой операции. В отличии от глобального, от него требуется лишь строгая монотонность во времени, то есть достаточно счетчика, увеличивающегося при обработке событий.

Некоторые операции могут порождать несколько элементов из одного, например  выпрямляющее отображение. Чтобы различать результаты к локальному времени добавим номер ребенка. Для отображений 1 в 1 номер ребенка будет равен нулю.

\[LocalEvent := (localTime, childId)\]

Аналогично глобальному времени локальное событие будем сравнивать лексикографически: вначале локальное время, потом номер ребенка.

Таким образом в каждый момент времени c каждым элементом протекающем по графу ассоциирована мета-информация: глобальное время и массив локальных времен операций, через который прошел элемент к данному времени.

\[Trace := [LocalEvent]\]
\[Meta := (GlobalTime, Trace)\]
\[DataItem := (payload, Meta)\]

В дальнейшем DataItem будем называть элементом. Будет подразумеваться, что у него есть некоторое глобальное время и след, может быть пустой, если он только что был порожден на фронте.

Мета-информацию будем сравнивать тоже лексикографически: глобальное время, потом след. В дальнейшем будет введено еще несколько порядков на мета-информации. Данный назовем естественным порядком.

\subsection{Операции}

Для построения логического графа используется следующий ограниченный набор операций:

\begin{itemize}
  \item отображение без состояния (map)
  \item выпрямляющее отображение (flatMap)
  \item группировка с окном по хешу (group)
  \item репликация (broadcast)
  \item слияние (merge).
\end{itemize}

\textbf{Отображение без состояния} применяет заданную функцию к входному элементу. Выходной элемент имеет глобальное время входного. А к следу прибавляется локальное время узла. Как понятно из названия, эта операция не имеет внутреннего состояния. Обработка двух элементов не зависит ни от порядка ни от локальности.

\textbf{Выпрямляющее отображение} сопоставляет каждому входному элементу множество выходных. Каждый элемент выходного множества впоследствии рассматривается как независимый. Все выходные элементы имеют глобальное время входного, к следу добавляется одинаковое локальное время но разный номер ребенка.

\textbf{Группировка с окном по хешу} последовательности входных элементов сопоставляет последовательность кортежей, размером с окно. Группировка в разных хешах выполняется независимо.

Например, если на вход подается последовательность натуральных чисел: \(1, 2, 3...\) , хешем является четность числа и окно - 3, то на выходе будет следующий набор кортежей:

\[(1), (2), (1|3), (2|4), (1|3|5), (2|4|6), (3|5|7)...\]

В отличии от партицирования по хешу, в данном случае хеш является частью логики. При этом хеш самой операции, который задает партицирование имеет смысл делать равным логическому хешу группинга.

Группировка - единственная операция в нашей системе обладающая состоянием - текущая история по хешу. Соответветственно результат операции зависит от порядка входных элементов, но результаты разных хешей независимы друг от друга. Гарантируется, что в рамках хеша результат будет такой же, каким был бы, если элементы на вход подаются в соответствии с глобальным временем. Про то, как это было получено будет рассказано в следующей главе.

Важным свойством такой семантики является то, что результат группировки однозначно определяется последним элементом в кортеже. Следовательно группировка это биективное отображение. Будем говорить, что этот кортеж защищается своим последним элементом.

Глобальным временем выходного элемента является глобальное время последнего элемента в кортеже. Следом - след последнего плюс локальное время группировки.

\textbf{Слияние} - операция с конечным числом входов и одним выходом. Каждый элемент с каждого входа подается на выход. Никаких гарантий на порядок не дается. К следу элемента добавляется локальное время операции.

\textbf{Репликация} обладает одним входном и множеством выходов.  Каждый элемент с входа подается, реплицируется на каждый выход. Аналогично выпрямлению все выходные элементы имеют глобальное время входного, к следу добавляется одинаковое локальное время но разный номер ребенка.

\begin{figure}
  \centering
	\includegraphics[width=0.7\textwidth]{pics/ops.png}
	\caption{Операции}
\end{figure}

\subsection{Поддержание семантики группировки}

При исполнении графа на кластере, операции разнесены по разным физическим хостам, более того на одной машине операции разнесены по разным потокам. В графе возможны репликации, слияния, циклы. В этих условиях невозможно поддерживать порядок элементов, которые подаются на вход операций.

К счастью единственной операцией для которой принципиален порядок входных данных - группировка.

Для поддержания семантики каждая операция группировки будет хранить всю историю элементов, которые были поданы на вход. Назовем эту историю буфером. Поскольку группировка по различным хешам независима, такой буфер будет различным для каждого хеша. Элементы в буфере будут храниться в порядке порождения, то есть отсортированы по глобальному времени. В главе “Минимальное время” будет показана оптимизация, позволяющая чистить буфер.

Как только приходит новый элемент он вставляется в правильную позицию в буфер. Если он самый новый в буфере, пришел в правильном порядке, то собирается обычный кортеж размером с окно и подается на выход. Если же он не самый старый, то инициируется перепроигрывание. Начинают заново порождаться кортежи, которые содержат новоприбывший элемент.

Таким образом группировка рано или поздно породит корректные кортежи. Проблемой является то, что в потоке так же будут находиться и некорректные. В этой главе мы введем необходимые определения и покажем, как определяется и удаляются некорректные элементы. Для этого достаточно будет сравнивать мета-информацию элементов.

\subsubsection{Отношение зависимости}

Введем на множестве элементов отношение зависимости.

Элемент \(d_1\) зависит от \(d_0\) тогда и только тогда, когда:

\begin{itemize}
  \item они имеют одинаковое GlobalTime
  \item \(trace(d_0)\) является префиксом \(trace(d_1)\)
  \item \(|trace(d_0)| == |trace(d_1)| - 1\)
\end{itemize}

\textit{Обозначение}: \(d_0 \rightarrow d_1\). \(d_0\) - родитель \(d_1\).

Транзитивное замыкание отношения непосредственной зависимости будем называть просто зависимостью. \textit{Обозначение}: \(d_0 \rightarrow^* d_7\). \(d_0\) - предок \(d_7\)

Каждый элементе имеет корень - элемент, имеющий такое же глобальное время и пустой след.

\begin{itemize}
  \item отображение без состояния: выходной - ребенок входного
  \item выпрямляющее отображение: каждый выходной - ребенок входного, между собой они братья
  \item группировка: выходной - ребенок входного
  \item репликация: каждый выходной - ребенок входного, при этом между собой они братья
  \item слияние: выходной - ребенок входного
\end{itemize}

\subsubsection{Отношение инвалидации}

Группировка является отображением 1 в 1. При перепроигрывании, порождаются кортежи, которые защищаются одинаковыми элементами. Задача инвалидации состоит в том, чтобы определить, какой из кортежей с одинаковыми защищающим элементом самый актуальный. То есть выделить корректное отображение.

У валидных кортежей будет то же глобальное время, что и у невалидных (см. описание группировки) но локальное время будет строго больше, поскольку они были возвращены позже. Введем отношение инвалидации.

Элемент \(d'\) инвалидирует \(d\) тогда и только тогда, когда:

\begin{itemize}
    \item они имеют одинаковое GlobalTime
    \item \(\exists j: (\forall i < j (trace(d)i = trace(d')_i) \\ \& localTime(trace(d)_j) < localTime(trace(d')_j)\)
\end{itemize}

То есть следы имеют общий префикс и событие следующее за префиксом строго позже. Если они имеют одинаковое локальное время, но разные номера детей - они несравнимы.

Будем называть элемент валидным, если не существует элементов инвалидирующих его. Невалидным - в противном случае.

Заметим, что невалидность сохраняется при применениии последующих операций: след только увеличивается. А валидность - при применении всех операций, кроме группировки, она может внести свое перепроигрывание и соответственно невалидность. Один раз невалидный - всегда невалидный.

\subsubsection{Перепроигрывание}

Опишем точнее, когда и как происходит перепроигрывание.

При добавлении нового элемента сначала находится определяется буфер, в который он будет добавлен. Для этого берется хеш от элемента. После находится позиция, на которую он должен встать в буфере. Если в буфере есть элементы, который он инвалидирует, то их надо удалить из буфера. Если таких нет, то новый элемент встает на позицию в соответствии с естественным порядком определенным в главе “Время”.

После добавления начинается перепроигрывание вокруг позиции новоприбывшего элемента. Возвращаются все кортежи, которые содержат новый элемент. В частности, если он встает на последнюю позицию, то возвращается только один кортеж: кортеж, который защищается этим элементом.

\begin{figure}
  \centering
	\includegraphics[width=1.0\textwidth]{pics/invalid.png}
	\caption{Перепроигрывание}
\end{figure}

\section{Построение инвертированного индекса на модели}

Рассмотрим в качестве примера использования построение инвертированного индекса. Для построения инвертированного индекса вводится две сущности: список словопозиций для конкретного слова в рамках одного документа и общий список словопозиций для конкретного слова (инвертированный индекс для конкретного слова). Обе эти сущности содержат внутри себя слово, хеш от которого участвует в операции группировки. Следует отметить, что обе сущности находятся внутри потока данных.

Для реализации бизнес-логики достаточно двух операций отображения и одной операции группировки. Первое отображение преобразует документ в список словопозиций для конкретного слова. Затем операция группировки группирует полученный список с инвертированным индексом для этого конкретного слова. Последнее отображение обновляет индекс с помощью полученного списка, выдает результат в виде разницы между предыдущей версией индекса и обновленной, и отправляет индекс на вход группировке для следующей итерации. Схема обработки показана на рисунке 1.

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{pics/II.png}
\caption{Схема построения инвертированного индекса}
\end{figure}

\section*{Заключение}

В данной работе был описан новый подход к потоковой обработке больших данных. В соответствии с данным походом была реализована программная система. В ближайшее время планируется развернуть систему на кластере и получить результаты бенчмарков в распределенном случае.

\setmonofont[Mapping=tex-text]{CMU Typewriter Text}
\bibliographystyle{ugost2008ls}
\bibliography{diploma.bib}
\end{document}
